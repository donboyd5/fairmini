# Equations

## Model summary

There are three consumption equations, three investment equations, a demand for imports equation, a price equation, the Fed’s interest rate rule, and a term structure equation explaining the mortgage rate. The equations are estimated by two-stage least squares (2SLS) with account taken, when necessary, of serial correlation of the residuals. The estimation period is 1954:1–2014:4 except for the Fed rule, where the period ends in 2008:3. (p.3)

## Data notes

FMFP.ZIP\sonyc\fm has:

-   fmage.txt with AG1, AG2, AG3 – SMPL 1952.1 2027.4 ; – the age variables
-   fmdata.txt – ALL of the other endogenous input variables
-   fmexog.txt – exogenous values
-   fminput.txt – has the FULL FairModel with 30 equations (US MODEL JANUARY 31, 2025 SPACE MAXVAR=500 MAXS=30 MAXCOEF=30 MAXFSR=60 FIRSTPER=1952.1 LASTPER=2027.4;)
-   fmout.txt – output from estimation and solution of the model

## Variables

Nominal variables are denoted with a \$ at the end. The stock variables are summed from flows, where the base-quarter value is given in the table. The summation when relevant is both forward and backward. The variables constructed from peak-to-peak interpolations are on straight lines between the peaks. The capital gain or loss variable, CG\$, is constructed from Flowof Funds data. Likewise, the construction of PHOUSE, the price of housing relative to the GDP deflator, uses Flow of Funds data.

![](images/clipboard-12052982.png)

![](images/clipboard-846148252.png)

![](images/clipboard-844145962.png)

## Identities

![](images/clipboard-4026653370.png)

## Time-varying constants

From his mini-model (pp.):

>An attempt is made in some equations to try to pick up a time varying relationship. It is hard with macro data to do much, but some significant estimates of a time varying constant term have been picked up. The assumption made, for a sample from 1 through T, is that the constant term is the same up to some observation T1, then changes linearly up to some observation T2, and is then unchanged at the T2 value through T. The estimate of C2 in the tables for an equation is the estimate
of the slope. The estimate of C is the estimate of the constant term up to T1. If the estimate of C2 is significant, this is evidence in favor of time variation of the constant term. After some experimentation, **T1 was taken to be 1969:4 for all the equations and T2 was taken to be 1988:4**. For more discussion see MM (Section
2.3.2).

From MM:

>The above discussion of single equation estimation does not consider the case of time varying coefficients. It is hard to deal with this case when using macro data because the variation in the data is generally not large enough to allow more than a few coefficients to be estimated per equation with any precision. Postulating time varying coefficients introduces more coefficients to estimate per equation, which can be a problem. A method is proposed in this subsection for dealing with one type of time varying coefficients that may be common in macro equations. The method is used in Section 3.6 for some of the U.S. equations in the MC model.

>A common assumption in the time varying literature is that coefficients follow random walks—see, for example, Stock and Watson (1998). This assumption is problematic in macro work since it does not seem likely that macroeconomic relationships change via randomwalk coefficients or similar assumptions. It seems more likely that they change in slower, perhaps trend like, ways. Also, it seems unlikely that changes take place over the entire sample period. If there is a change, it may begin after the beginning of the sample period and end before the end of the sample period. The assumption used here postulates no change for a while, then smooth trend change for a while, and then no change after that. The assumption can be applied to any number of coefficients in an equation, although it is probably not practical with macro data to deal with more than one or two coefficients per equation.

IOW: constant term is same up to 1969:4 (T1), then changes linearly up to some 1988:4 (T2) and unchanged through T

## Prepare data

```{r}
#| label: notes

# AG1 exog Percent of 16+ population 26-55 minus percent 16-25. BLS data. 1, 2, 3 -- working age minus college age
# AG2 exog Percent of 16+ population 56-65 minus percent 16-25. BLS data. 1, 2, 3 -- early retirement minus college age
# AG3 exog Percent of 16+ population 66+ minus percent 16-25. BLS data. 1, 2, 3   -- elderly minus college age

```


```{r}
#| label: setup

library(here)
library(tidyverse)
library(fs)
library(zoo)

library(AER) 
library(systemfit)

source(here::here("R", "functions_eviews.R"))

dfair <- r"(E:\R_projects\projects\fairmini\data_raw\FMFP)"


```

```{r}
#| label: get-data

fn <- "fmage.txt"; fpath <- fs::path(dfair, fn)
fmages <- get_eviews(fpath)
fmages |> 
  unnest(cols = data)

fn <- "fmdata.txt"; fpath <- fs::path(dfair, fn)
fmdata <- get_eviews(fpath)


```


```{r}
#| label: eq1

# C constant
# C2 exog time varying constant term. 1, 2, 3, 4, 5, 6, 7, 8
# AA AG1, AG2, AG3 C, C2 CS POP RS YD

vars <- c("AA", "C", "C2", "CS", "POP", "RS", "YD")

eqd1 <- fmdata |> 
  filter(vname %in% vars) |> 
  bind_rows(fmages)

count(eqd1, vname) # AA, CS, POP, RS, YD
# need C, C2
# constant term is same up to 1969:4 (T1), then changes linearly up to some 1988:4 (T2) and unchanged through T

# C2 parameters
T1 <- "1969-10-01"
T2 <- "1988-10-01"


eqd2 <- eqd1 |> 
  select(-c(start, end)) |> 
  unnest(cols = data) |> 
  pivot_wider(names_from = vname) |> 
  arrange(date) |> 
  mutate(aa_pop = AA / POP,
         cs_pop = CS / POP,
         yda_pop = YD / POP,
         ln_cs_pop = log(cs_pop),
         ln_aa_pop_l1 = lag(log(aa_pop)),
         ln_cs_pop_l1 = lag(ln_cs_pop),
         ln_yda_pop = log(yda_pop),
         idx = row_number(),
         C = 1,
         C2 = case_when(
           date < T1 ~ 0,
           date < T2 ~ idx - idx[date == T1],
           date >= T2 ~ idx[date == T2] - idx[date == T1],
           .default = NA_real_)) |> 
  # get additional lagged values possibly needed for instrumental variables
  mutate(ln_cs_pop_l2  = lag(ln_cs_pop, 2),
         RS_l1         = lag(RS)) |> 
  na.omit() # drop any row that has an NA in any variable

eqd2 
summary(eqd2)

```



## Equation 1 – log of real per-capita consumption of services

```{r}
#| label: by-hand


# estimation period
# 1954.1 2014.4

eqd3 <- eqd2 |> 
  filter(date >= "1954-01-01",
         date <= "2014-10-01")
summary(eqd3)

# structural equation 
equation_1_form <- ln_cs_pop ~ C + C2 + AG1 + AG2 + AG3 +
                              ln_cs_pop_l1 + ln_yda_pop + RS + ln_aa_pop_l1

# define the instruments; typically for 2SLS we also use all exogenous variables plus suitable lags
instruments_1   <- ~ C + C2 + AG1 + AG2 + AG3 +
                    ln_cs_pop_l1 + ln_cs_pop_l2 + ln_yda_pop + RS_l1 + ln_aa_pop_l1

fit_plain <- ivreg(formula      = equation_1_form,
                   instruments  = instruments_1,
                   data         = eqd3)
summary(fit_plain)

res_plain <- residuals(fit_plain)

# 2) Estimate AR(1) parameter  (rho) from plain 2SLS residuals ----

eqd3a <- eqd3 |> 
  mutate(
    u_plain    = res_plain,
    u_plain_l1 = lag(u_plain)
    ) |> 
  na.omit() # drop first row that lacks the lag


do_ar1_iteration <- function(rho_old, data_in) {
  
  data_out <- data_in  |> 
    mutate(
      # Left-hand side, starred
      ln_cs_pop_star    = ln_cs_pop - rho_old * lag(ln_cs_pop),
      
      # Regressors, starred
      C_star            = C - rho_old * lag(C),
      C2_star           = C2 - rho_old * lag(C2),
      AG1_star          = AG1 - rho_old * lag(AG1),
      AG2_star          = AG2 - rho_old * lag(AG2),
      AG3_star          = AG3 - rho_old * lag(AG3),
      ln_cs_pop_l1_star = ln_cs_pop_l1 - rho_old * lag(ln_cs_pop_l1),
      ln_yda_pop_star   = ln_yda_pop - rho_old * lag(ln_yda_pop),
      RS_star           = RS - rho_old*lag(RS),
      ln_aa_pop_l1_star = ln_aa_pop_l1 - rho_old * lag(ln_aa_pop_l1),
      
      # Star the instruments as well:
      ln_cs_pop_l2_star = ln_cs_pop_l2 - rho_old * lag(ln_cs_pop_l2),
      RS_l1_star        = RS_l1 - rho_old * lag(RS_l1),
      
      # transform the old residual for re-estimating rho
      u_plain_star      = u_plain - rho_old * lag(u_plain)
    )
  
  data_out <- na.omit(data_out)
  # Now do 2SLS on starred eqn
  eqn_star <- ln_cs_pop_star ~ C_star + C2_star + AG1_star + AG2_star + AG3_star +
                               ln_cs_pop_l1_star + ln_yda_pop_star + RS_star + ln_aa_pop_l1_star
  
  inst_star <- ~ C_star + C2_star + AG1_star + AG2_star + AG3_star +
                 ln_cs_pop_l1_star + ln_cs_pop_l2_star + ln_yda_pop_star + RS_l1_star + ln_aa_pop_l1_star
  
  fit_star <- ivreg(eqn_star, inst_star, data=data_out)
  
  # residuals from that starred regression
  res_star <- residuals(fit_star)
  data_out$u_star <- res_star  
  
  # OLS of u_star on lag(u_star) to get new rho
  data_out <- data_out %>% mutate(u_star_l1 = lag(u_star,1)) %>% na.omit()
  rho_new <- coef(lm(u_star ~ u_star_l1, data=data_out))[2]
  
  list(fit=fit_star, data=data_out, rho=rho_new)
}

max_iter    <- 1000
tol         <- 1e-5
rho_current <- coef(lm(u_plain ~ u_plain_l1, data=eqd3a))[2]   # initial guess
rho_current
cat("Initial guess for rho =", rho_current,"\n")

final_out <- NULL
for (k in 1:max_iter) {
  out_k <- do_ar1_iteration(rho_current, eqd3a)
  rho_new <- out_k$rho
  cat(sprintf("Iteration %d: old rho=%.5f, new rho=%.5f\n",k, rho_current, rho_new))
  if (abs(rho_new - rho_current)<tol) {
    cat("Converged.\n")
    final_out <- out_k
    break
  }
  rho_current <- rho_new
  final_out   <- out_k
}

final_fit <- final_out$fit
cat("Final AR(1) coefficient (rho) =", final_out$rho,"\n")
summary(final_fit)
summary(eqd3a)
glimpse(eqd3a)

# final_fit is your "starred" regression. The reported coefficient
# estimates correspond to the structural eqn(1) parameters.
# Done!
# 



```



```{r}
#| label: system-fit



# system fit approach ----
# estimation period
# 1954.1 2014.4

# eqn1 <- log(CS/POP) ~ C + C2 + AG1 + AG2 + AG3 +
#                       lag(log(CS/POP),1) + log(YD/POP) +
#                       RS + lag(log(AA/POP),1)

eqn1 <- log(CS/POP) ~ C + C2 + AG1 + AG2 + AG3 +
                      lag(log(CS/POP),1) + log(YD/POP) +
                      RS + lag(log(AA/POP),1)

instr1 <- ~ C + C2 + AG1 + AG2 + AG3 +
          lag(log(CS/POP),1) + lag(log(CS/POP),2) +
          lag(log(YD/POP),1) + lag(RS,1) + lag(log(AA/POP),1)

eqn1 <- log(CS/POP) ~ C2 + AG1 + AG2 + AG3 +
                      lag(log(CS/POP),1) + log(YD/POP) +
                      RS + lag(log(AA/POP),1)

instr1 <- ~ C2 + AG1 + AG2 + AG3 +
          lag(log(CS/POP),1) + lag(log(CS/POP),2) +
          lag(log(YD/POP),1) + lag(RS,1) + lag(log(AA/POP),1)



eqns  <- list(eqn1 = eqn1)   # even though just one equation, we must pass a list
insts <- list(eqn1 = instr1)

fit   <- systemfit(eqns,
                   method="2SLS",
                   inst=insts,
                   data=eqd2 |> 
                     filter(date >= "1954-01-01",
                            date <= "2014-10-01"))
summary(fit)

# fit_ar1 <- systemfit(eqns,
#                      method="2SLS",
#                      inst=insts,
#                      data=eqd2 |> 
#                      filter(date >= "1954-01-01",
#                             date <= "2014-10-01"),
#                      rho=rep(0,1),    # initial guess for the AR(1) coefficient
#                      maxit=20,       # max number of iterations
#                      methodResidCov="AR1")
# summary(fit_ar1)




# 

```


### Variables

AA

AG1, AG2, AG3

C, C2

CS

POP

RS

YD

![](images/clipboard-505718086.png)
